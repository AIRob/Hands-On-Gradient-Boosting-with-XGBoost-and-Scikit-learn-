{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset 'census_cleaned.csv'\n",
    "df_census = pd.read_csv('census_cleaned.csv')\n",
    "\n",
    "# Split data into X and y\n",
    "X = df_census.iloc[:,:-1]\n",
    "y = df_census.iloc[:,-1]\n",
    "\n",
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8131679154894976"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Decision Tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize classification model\n",
    "clf = DecisionTreeClassifier(random_state=2)\n",
    "\n",
    "# Fit model on training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download bike_rentals_cleaned dataset\n",
    "df_bikes = pd.read_csv('bike_rentals_cleaned.csv')\n",
    "\n",
    "# split data into X and y\n",
    "X_bikes = df_bikes.iloc[:,:-1]\n",
    "y_bikes = df_bikes.iloc[:,-1]\n",
    "\n",
    "# Import Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bikes, y_bikes, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE mean: 1233.36\n"
     ]
    }
   ],
   "source": [
    "# Initialize Decision Tree Regressor\n",
    "reg = DecisionTreeRegressor(random_state=2)\n",
    "\n",
    "# Obtain scores of cross-validation using mean squared error\n",
    "scores = cross_val_score(reg, X_bikes, y_bikes, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Take square root of the scores\n",
    "rmse = np.sqrt(-scores)\n",
    "\n",
    "# Display mean score\n",
    "print('RMSE mean: %0.2f' % (rmse.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-807cf72c0376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mreg_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mreg_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg_mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mreg_rmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "reg = DecisionTreeRegressor()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_train)\n",
    "reg_mse = mean_squared_error(y_train, y_pred)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "reg_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Decision Tree Regressor\n",
    "reg = DecisionTreeRegressor(random_state=2, max_depth=6)\n",
    "\n",
    "# Obtain scores of cross-validation using mean squared error\n",
    "scores = cross_val_score(reg, X_bikes, y_bikes, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Take square root of the scores\n",
    "rmse = np.sqrt(-scores)\n",
    "\n",
    "# Display mean score\n",
    "print('RMSE mean: %0.2f' % (rmse.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Choose max_depth hyperparameters\n",
    "params = {'max_depth':[None,2,3,4,6,8,10,20]}\n",
    "\n",
    "# Initialize regression model as reg\n",
    "reg = DecisionTreeRegressor(random_state=2)\n",
    "\n",
    "# Initialize GridSearchCV as grid_reg\n",
    "grid_reg = GridSearchCV(reg, params, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit grid_reg on X_train and y_train\n",
    "grid_reg.fit(X_train, y_train)\n",
    "\n",
    "# Extract best parameters\n",
    "best_params = grid_reg.best_params_\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute best score\n",
    "best_score = np.sqrt(-grid_reg.best_score_)\n",
    "\n",
    "# Print best score\n",
    "print(\"Training score: {:.3f}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best model\n",
    "best_model = grid_reg.best_estimator_\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Import mean_squared_error from sklearn.metrics as MSE \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Compute rmse_test\n",
    "rmse_test = mean_squared_error(y_test, y_pred)**0.5\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test score: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(params, reg=DecisionTreeRegressor(random_state=2)):\n",
    "\n",
    "    # Instantiate GridSearchCV as grid_reg\n",
    "    grid_reg = GridSearchCV(reg, params, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "    \n",
    "    # Fit grid_reg on X_train and y_train\n",
    "    grid_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Import mean_squared_error from sklearn.metrics as MSE \n",
    "    from sklearn.metrics import mean_squared_error as MSE_\n",
    "\n",
    "    # Extract best params\n",
    "    best_params = grid_reg.best_params_\n",
    "\n",
    "    # Print best params\n",
    "    print(\"Best params:\", best_params)\n",
    "    \n",
    "    # Compute best score\n",
    "    best_score = np.sqrt(-grid_reg.best_score_)\n",
    "\n",
    "    # Print best score\n",
    "    print(\"Training score: {:.3f}\".format(best_score))\n",
    "\n",
    "    # Predict test set labels\n",
    "    y_pred = grid_reg.predict(X_test)\n",
    "\n",
    "    # Compute rmse_test\n",
    "    rmse_test = MSE(y_test, y_pred)**0.5\n",
    "\n",
    "    # Print rmse_test\n",
    "    print('Test score: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'min_samples_leaf':[1,2,4,6,8,10,20,30]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'max_depth':[None,2,3,4,6,8,10,20],'min_samples_leaf':[1,2,4,6,8,10,20,30]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'max_depth':[5,6,7,8,9],'min_samples_leaf':[3,5,7,9]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study - Heart Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload heart.csv to dataFrame\n",
    "df_heart = pd.read_csv('heart_disease.csv')\n",
    "\n",
    "# Show first five rows\n",
    "df_heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "X = df_heart.iloc[:,:-1]\n",
    "y = df_heart.iloc[:,-1]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Decision Tree Classifier\n",
    "model = DecisionTreeClassifier(random_state=2)\n",
    "\n",
    "# Obtain scores of cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "# Display accuracy\n",
    "print('Accuracy:', np.round(scores, 2))\n",
    "\n",
    "# Display mean accuracy\n",
    "print('Accuracy mean: %0.2f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def randomized_search_clf(params, runs=20, clf=DecisionTreeClassifier(random_state=2)):\n",
    "\n",
    "    # Instantiate GridSearchCV as grid_reg\n",
    "    rand_clf = RandomizedSearchCV(clf, params, n_iter=runs, \n",
    "                                  cv=5, n_jobs=-1, random_state=2)\n",
    "    \n",
    "    # Fit grid_reg on X_train and y_train\n",
    "    rand_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Extract best estimator\n",
    "    best_model = rand_clf.best_estimator_\n",
    "    \n",
    "    # Extract best score\n",
    "    best_score = rand_clf.best_score_\n",
    "\n",
    "    # Print best score\n",
    "    print(\"Training score: {:.3f}\".format(best_score))\n",
    "\n",
    "    # Predict test set labels\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Print accuracy\n",
    "    print('Test score: {:.3f}'.format(accuracy))\n",
    "        \n",
    "    # Return best model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_search_clf(params={'criterion':['entropy', 'gini'],\n",
    "                              'splitter':['random', 'best'],\n",
    "                          'min_weight_fraction_leaf':[0.0, 0.0025, 0.005, 0.0075, 0.01],\n",
    "                          'min_samples_split':[2, 3, 4, 5, 6, 8, 10],\n",
    "                          'min_samples_leaf':[1, 0.01, 0.02, 0.03, 0.04],\n",
    "                          'min_impurity_decrease':[0.0, 0.0005, 0.005, 0.05, 0.10, 0.15, 0.2],\n",
    "                          'max_leaf_nodes':[10, 15, 20, 25, 30, 35, 40, 45, 50, None],\n",
    "                          'max_features':['auto', 0.95, 0.90, 0.85, 0.80, 0.75, 0.70],\n",
    "                          'max_depth':[None, 2,4,6,8],\n",
    "                          'min_weight_fraction_leaf':[0.0, 0.0025, 0.005, 0.0075, 0.01, 0.05]\n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_search_clf(params={'max_depth':[None, 6, 7],\n",
    "'max_features':['auto', 0.78],\n",
    "'max_leaf_nodes':[45, None],\n",
    "'min_samples_leaf':[1, 0.035, 0.04, 0.045, 0.05],\n",
    "'min_samples_split':[2, 9, 10],\n",
    "'min_weight_fraction_leaf': [0.0, 0.05, 0.06, 0.07],\n",
    "},\n",
    "runs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Decision Tree Classifier\n",
    "model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
    "            max_features=0.78, max_leaf_nodes=45,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=0.045, min_samples_split=9,\n",
    "            min_weight_fraction_leaf=0.06, presort=False, random_state=2,\n",
    "            splitter='best')\n",
    "\n",
    "# Obtain scores of cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "# Display accuracy\n",
    "print('Accuracy:', np.round(scores, 2))\n",
    "\n",
    "# Display mean accuracy\n",
    "print('Accuracy mean: %0.2f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
    "                       max_features=0.78, max_leaf_nodes=45,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=0.045, min_samples_split=9,\n",
    "                       min_weight_fraction_leaf=0.06, presort=False,\n",
    "                       random_state=2, splitter='best')\n",
    "best_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip columns and feature_importances_ into dict\n",
    "feature_dict = dict(zip(X.columns, best_clf.feature_importances_))\n",
    "\n",
    "# Import operator\n",
    "import operator\n",
    "\n",
    "# Sort dict by values (as list of tuples)\n",
    "sorted(feature_dict.items(), key=operator.itemgetter(1), reverse=True)[0:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
